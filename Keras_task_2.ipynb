{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Import Required Libraries***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H2kV_NLymknN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(2)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop, Adam, Adadelta, Adagrad, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Conv2D, MaxPooling2D, Activation\n",
    "from keras import backend as K\n",
    "from keras.backend import sigmoid\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Swish Activation Function**\n",
    "\n",
    "I was trying to train the model with Swish activation function too but it did not help much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FEkuQ23WhYTS"
   },
   "outputs": [],
   "source": [
    "def swish(x, beta = 1):\n",
    "    return (x * sigmoid(beta * x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U9d-VlcqhewC"
   },
   "outputs": [],
   "source": [
    "get_custom_objects().update({'swish': Activation(swish)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mNvxbVx8higc"
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R5jFWMIfhmb8"
   },
   "outputs": [],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zfy-eV0jhu8k"
   },
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "I have implemented grayscale normalization to reduce the effect of illumination's differences and CNN converg faster on (0-1) than on (0-255)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "34b6a5f7-8fd2-4387-8ef4-c9dc19584fed",
    "_execution_state": "idle",
    "_uuid": "f0a6ad80dab8e0f2c2e46165ccd9cd82dd162bc3",
    "colab": {},
    "colab_type": "code",
    "id": "Ikb_R4HGjqPE"
   },
   "outputs": [],
   "source": [
    "# Reshape image in 3 dimensions\n",
    "x_train = x_train.reshape(-1,28,28,1)\n",
    "x_test = x_test.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Keras requires an extra dimension in the end which correspond to channels. MNIST images are gray scaled so it use only one channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "hIVvsii-kE4N",
    "outputId": "74ac16dd-c702-4a6a-d750-ce025045a2a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_236\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_941 (Conv2D)          (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "conv2d_942 (Conv2D)          (None, 28, 28, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_471 (MaxPoolin (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_943 (Conv2D)          (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_944 (Conv2D)          (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_472 (MaxPoolin (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_236 (Flatten)        (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_469 (Dense)            (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_470 (Dense)            (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 933,130\n",
      "Trainable params: 932,362\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(10, activation = \"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "I have added two extra layers of Convolution to extract more abstract features from the images. I have also replaced dropout layer with batch normalization as they both are regularization techniques but it did not help much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kobIQ_3LmLvF"
   },
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = Adam(lr=0.001, epsilon=1e-08, decay=0.0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "I have used Adam optimizer instead of the previous 'Adadelta' because, it is just Adadelta (which rescales gradients based on accumulated \"second-order\" information) plus momentum (which smooths gradients based on accumulated \"first-order\" information) and in majority of the cases, it outperforms AdaDelta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JlAN5oo7mL7w"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WEhkcs4TmMFX"
   },
   "outputs": [],
   "source": [
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "I have use learning rate decay functionality of keras to reduce the learning rate if the validation accuracy does not improve for 3 consecutive epochs, thus it makes the optimization more efficient/faster. It makes sure that we are not missing the local minima. Alongwith that, I have also used early stopping functionality of keras in the callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rf-1cM7RmMPC"
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wyS5ZPxtmxcV"
   },
   "outputs": [],
   "source": [
    "# Data Augmentation Using ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Here, I have used Image Augmentation to add more variety to the training dataset so that it accommodate with unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "iZy3F1iqm2Cq",
    "outputId": "d05a736b-2c68-42bf-d7c6-515b14103155"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 26s - loss: 0.1394 - acc: 0.9564 - val_loss: 0.0822 - val_acc: 0.9746\n",
      "Epoch 2/10\n",
      " - 19s - loss: 0.0584 - acc: 0.9823 - val_loss: 0.0498 - val_acc: 0.9837\n",
      "Epoch 3/10\n",
      " - 19s - loss: 0.0457 - acc: 0.9859 - val_loss: 0.1321 - val_acc: 0.9576\n",
      "Epoch 4/10\n",
      " - 20s - loss: 0.0405 - acc: 0.9871 - val_loss: 0.0338 - val_acc: 0.9899\n",
      "Epoch 5/10\n",
      " - 20s - loss: 0.0379 - acc: 0.9881 - val_loss: 0.0476 - val_acc: 0.9867\n",
      "Epoch 6/10\n",
      " - 20s - loss: 0.0318 - acc: 0.9901 - val_loss: 0.0200 - val_acc: 0.9934\n",
      "Epoch 7/10\n",
      " - 20s - loss: 0.0314 - acc: 0.9901 - val_loss: 0.0246 - val_acc: 0.9920\n",
      "Epoch 8/10\n",
      " - 20s - loss: 0.0308 - acc: 0.9903 - val_loss: 0.0173 - val_acc: 0.9947\n",
      "Epoch 9/10\n",
      " - 20s - loss: 0.0259 - acc: 0.9920 - val_loss: 0.0182 - val_acc: 0.9935\n",
      "Epoch 10/10\n",
      " - 20s - loss: 0.0263 - acc: 0.9918 - val_loss: 0.0176 - val_acc: 0.9940\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),epochs = epochs, \n",
    "                              validation_data = (x_test,y_test),verbose = 2, \n",
    "                              steps_per_epoch=x_train.shape[0] // batch_size, \n",
    "                              callbacks=[learning_rate_reduction, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VKZfSdXVnHn5"
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "O2WWRqSKp9oQ",
    "outputId": "13395fb3-6f4c-4cbf-8022-6d3692a7001a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.994\n"
     ]
    }
   ],
   "source": [
    "print(score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bsnJOuVTp_rY"
   },
   "source": [
    "## Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is my ***second submission*** which exceeds the time limit of 1 hr. Here I have tried to make the code work better than my last submission. Though, I have tried many options with the explanation given above, but still other possibilities do exist, for ex: Using Hyperopt for finding out the best hyperparameter combinations, using OpenCV to preprocess image data and your additional requirement, i.e., using Classes to improve the aesthetics of the code."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
